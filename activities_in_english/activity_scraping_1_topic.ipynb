{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6f333bd-2609-4858-b410-1414c00cd3d6",
   "metadata": {},
   "source": [
    "# <center>Scraping Workshop</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e655cd2-053b-47a2-baf0-9eabfc01b7dc",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"./images/scrappeur.png\" width=\"600\" height=\"300\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f4c6a6-7867-4f2f-8653-df8ceea4569c",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeb85f9-b3c0-4541-a7cf-9085482f8cdb",
   "metadata": {},
   "source": [
    "Let's start by setting out the basics of scraping. \n",
    "\n",
    "Scraping means knowing how to read what's behind a site. With a simple right-click and `inspect`, it's fairly easy to access the HTML code of the page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a46eec-b1f5-46c9-837f-956dcef224c4",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"./images/du site au html.png\" width=\"800\" height=\"400\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16217df-9864-40bb-adce-41ef1fce2f45",
   "metadata": {},
   "source": [
    "Scraping consists of analysing the source code of a page for various applications:  \n",
    "\n",
    "- Locating elements and interacting with them to automate repetitive tasks (such as buttons, for example)\n",
    "- Extracting different types of information (which we'll be looking at in this workshop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a673eb-db4d-48ac-a680-2c1a2fc47a80",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4de42c-a92c-4cb0-a60f-edcd0f6904d2",
   "metadata": {},
   "source": [
    "Next, you need to choose a scraping tool: ***Selenium*** or ***BeautifulSoup***, which you can use to recover the various elements of a web page.\n",
    "\n",
    "- Selenium is useful for dynamic web pages where content is generated via JavaScript, requiring user interaction such as clicking, scrolling or text input.\n",
    "\n",
    "- BeautifulSoup is a Python library used primarily for parsing HTML and XML documents. It is useful for extracting structured data from static web pages.\n",
    "\n",
    "Generally speaking, we prefer to use Selenium, which allows more actions, but beautifulsoup remains an important option. In this activity, we present the two modules to help you get to grips with them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2df1779-bcb5-484f-827b-4bf04b2f3548",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b651b072-df16-4586-8b2b-6ea80422c1da",
   "metadata": {},
   "source": [
    "## Activity 1a: Retrieving a Professor Layton riddle with Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abe749d-4ac0-44b2-a5f4-a2a1d61f7b69",
   "metadata": {},
   "source": [
    "We're going to see how we can simply retrieve the main elements of a wiki page to create a database. To do this, we're going to connect to https://professeur-layton.fandom.com/fr/wiki/En_queue_de_poisson. \n",
    "\n",
    "The first step will be to retrieve :\n",
    "- the title\n",
    "- the riddle number\n",
    "- the statement\n",
    "- the solution\n",
    "- the solution\n",
    "- the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f454db-be86-4540-b80b-8f78634070c6",
   "metadata": {},
   "source": [
    "#### Importing python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1214a01e-fc63-46f2-9da7-d082a90e10cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee0ba2e-8543-4dc9-8b6c-5fb43f87c517",
   "metadata": {},
   "source": [
    "#### Launch the browser and connect to the riddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e40e8b8a-52fa-458a-8ab5-6ed70c070d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance of Chrome options\n",
    "chrome_options = Options()\n",
    "\n",
    "# Setting Chrome options \n",
    "chrome_options.add_argument('--disable-search-engine-choice-screen') \n",
    "chrome_options.add_argument('--disable-infobars')\n",
    "# Create a new instance of the Chrome browser with the specified options\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# Enter the URL you want to scrape and inject it into the :\n",
    "url = \"https://professeur-layton.fandom.com/fr/wiki/En_queue_de_poisson\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a7540-dfa1-4490-89b7-03ee3cc3af89",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9297082-e62b-4791-bdd7-c5bff09e02a1",
   "metadata": {},
   "source": [
    "If all has worked well, you should see a chrome window open at the URL we've provided. \n",
    "\n",
    "The site uses cookies, we could simply click on ‘ACCEPT ALL’ or ‘REFUSE ALL’ but we're going to use selenium to perform one of these actions. The next two code cells are very specific to the site we're trying to scrape, so we won't dwell on them :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aea1c8a5-178c-4c93-a51a-06f10c2008ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cookie = driver.find_element(By.CLASS_NAME ,'NN0_TB_DIsNmMHgJWgT7U')\n",
    "cookie.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1115dff0-2b04-494a-94c3-c0af195cf5b5",
   "metadata": {},
   "source": [
    "Next, we are going to scroll slightly so that the program can locate the various elements of the site (given the rather large advertising video at the top of the web page) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aefc3ac8-7a7e-4616-a42d-82b27f1c2f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the total height of the page\n",
    "total_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "# Calculate the scroll height (20% in this example)\n",
    "scroll_height = total_height * 0.20\n",
    "\n",
    "# 10% scroll\n",
    "driver.execute_script(f\"window.scrollBy(0, {scroll_height});\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afbea16-20ec-4923-a695-f1203c7a8a17",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21c2454-b1a4-4118-bb83-d7d7cfd31710",
   "metadata": {},
   "source": [
    "We will now look at how to retrieve the information from the instructions: the title, the riddle number, the statement, the solution and the resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd46d9c-4ce6-46d5-8a46-c1e06552e73f",
   "metadata": {},
   "source": [
    "#### Clever recovery of Web elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5560a9-487f-4a04-954c-0d411d2f3365",
   "metadata": {},
   "source": [
    "Here's a little [HTML Form](../form_html.md). It's a quick way of learning or remembering the main tags used to read HTML and identify the different elements of a web page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07ff8bf-f906-477d-aebe-12710764cbc4",
   "metadata": {},
   "source": [
    "This is where we introduce the various Web element selectors : \n",
    "\n",
    "- ID = \"id\"\n",
    "- NAME = \"name\"\n",
    "- XPATH = \"xpath\"\n",
    "- LINK_TEXT = \"link text\"\n",
    "- PARTIAL_LINK_TEXT = \"partial link text\"\n",
    "- TAG_NAME = \"tag name\"\n",
    "- CLASS_NAME = \"class name\"\n",
    "- CSS_SELECTOR = \"css selector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b89c775-44ab-4254-8400-1a71f7eadd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title recovery :\n",
    "title = driver.find_element(By.ID, 'firstHeading')\n",
    "\n",
    "# Riddle number retrieval :\n",
    "num_enigme = driver.find_element(By.XPATH ,'//*[@id=\"mw-content-text\"]/div/div[1]/div[2]/table/tbody/tr[4]/td')\n",
    "\n",
    "# Retrieve the riddle statement :\n",
    "enonce = driver.find_element(By.ID, \"Énoncé\")\n",
    "enigme_enonce = enonce.find_elements(By.XPATH, \"//span[@class='mw-headline' and @id='Énoncé']/ancestor::h2/following-sibling::p[following-sibling::h2]\")\n",
    "\n",
    "# Retrieving the answer :\n",
    "reponse = driver.find_element(By.XPATH, '//*[@id=\"mw-content-text\"]/div/p[8]')\n",
    "\n",
    "resolution = driver.find_element(By.ID, \"Résolution\")\n",
    "resolution_enonce = resolution.find_elements(By.XPATH, \"//span[@class='mw-headline' and @id='Résolution']/ancestor::h3/following-sibling::p[following-sibling::h3]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b1bc32-f286-4fcb-9f41-3149ebcb36d3",
   "metadata": {},
   "source": [
    "Find out what our variables contain and what type they are: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deb77a0e-91f7-4d9e-97bc-5879d9165d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"fbb51fe6914db4fc5a4ca44eb79e66c9\", element=\"f.65A58076A2D8875C15F6000527C46229.d.A360C40CD0FDB00724A24AF066159BD4.e.112\")>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a78eef78-68b9-4dd8-bed3-ba09f9442b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "selenium.webdriver.remote.webelement.WebElement"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca4c42b7-0ec8-436c-8d5a-e16f4d6ff788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"fbb51fe6914db4fc5a4ca44eb79e66c9\", element=\"f.65A58076A2D8875C15F6000527C46229.d.A360C40CD0FDB00724A24AF066159BD4.e.123\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"fbb51fe6914db4fc5a4ca44eb79e66c9\", element=\"f.65A58076A2D8875C15F6000527C46229.d.A360C40CD0FDB00724A24AF066159BD4.e.124\")>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resolution_enonce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fb0cd30-1ba7-4500-9cce-b9ed3ada5bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(resolution_enonce)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d45a493-7cc7-42f3-8929-83e1b98b4159",
   "metadata": {},
   "source": [
    "#### Reading Web elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6605ec55-cb20-4588-86d4-1852ab7f10fb",
   "metadata": {},
   "source": [
    "You will probably have noticed that we have used `find_element` in some cases and `find_elements` in others. \n",
    "\n",
    "The choice between these two methods depends on what we want to obtain. \n",
    "\n",
    "If we want to extract a single element, such as a title, we'll use `find_element`, because we only want to retrieve one element. \n",
    "\n",
    "On the other hand, if we want to retrieve several elements, such as the text tags for a statement or the solution to a puzzle, we'll use `find_elements`, as this allows us to retrieve several elements at once.\n",
    "\n",
    "This way of retrieving elements will have an impact on how they are read. The `.text` method is used to obtain the text of a WebElement.\n",
    "However, if you have a list of WebElements, the `.text` method will not be directly accessible, hence the following code : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43ab2d7f-d104-48c2-9a9b-bab9d8a34ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction of the WebElement title text\n",
    "title = title.text\n",
    "\n",
    "# Extract text from WebElement num_enigme\n",
    "num_enigme = num_enigme.text\n",
    "\n",
    "# Extract text from WebElements list enigme_enonce\n",
    "enigme_enonce = [elem.text for elem in enigme_enonce]\n",
    "enigme_enonce = \"\".join(enigme_enonce)\n",
    "\n",
    "# Extract the text from the WebElement response\n",
    "reponse = reponse.text\n",
    "\n",
    "# Extract text from WebElements list resolution_enonce\n",
    "resolution_enonce = [elem.text for elem in resolution_enonce]\n",
    "resolution_enonce = \"\".join(resolution_enonce)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d377e730-ebbf-4aae-8c74-ccee3087e128",
   "metadata": {},
   "source": [
    "#### Storage in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "079d8e96-471e-4c4b-8643-6492ec52ee80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'En queue de poisson', 'number': '053', 'enonce': 'Alors que vous aviez le dos tourné, quelqu\\'un a englouti le poisson que vous vous étiez préparé pour le dîner. Trois frères se trouvent à proximité des lieux du crime. Voici ce qu\\'ils ont a dire :A : \"Oui je l\\'ai mangé. C\\'était drôlement bon !\"\\nB : \"J\\'ai vu A manger le poisson !\"\\nC : \"B et moi n\\'y avons pas touché.\"L\\'un d\\'entre eux vous ment, mais qui ?', 'solution': 'La réponse est C.', 'resolution': \"Le menteur est le frère C. A et C se sont partagés votre dîner.La réponse devient évidente quand on réalise que si A ment, alors B ment obligatoirement. Le même raisonnement a lieu si l'on considère que B ment. La seule réponse possible est donc que C est en train de mentir, ce qui implique que C a également touché au poisson.\"}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the list dictionary\n",
    "data = {\n",
    "    'title': title,\n",
    "    'number': num_enigme,\n",
    "    'enonce': enigme_enonce,\n",
    "    'solution': reponse,\n",
    "    'resolution': resolution_enonce\n",
    "}\n",
    "# Display the dictionary\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7387a7-921e-4ba5-b75e-b5d6ce70a10c",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf31ceaf-4997-4ca5-931e-3bae040744ee",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"./images/learner_scraping.png\" width=\"300\" height=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af7d45e-0089-4ce0-84da-39d8f178dae8",
   "metadata": {},
   "source": [
    "And that's it ! We've made our first scrapbook !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff809294-f8ae-490c-978f-f0a397d0094f",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220ed283-9439-45bc-8579-38c92a8427a5",
   "metadata": {},
   "source": [
    "## Activity 1b: Retrieving a Professor Layton riddle with BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af911d8a-3dd1-4ebf-b582-2e8e72b06d04",
   "metadata": {},
   "source": [
    "We're going to do the same scraping, but this time with BeautifulSoup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e864852-a2ae-4ade-b39c-5b22ce681b9d",
   "metadata": {},
   "source": [
    "#### Importing python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b32e7519-3981-4e11-91a2-d9f313eadeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibliothèques\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "from typing import List\n",
    "import requests\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a05b38-e998-4ee4-90ae-3c148945110f",
   "metadata": {},
   "source": [
    "#### Launch a query to retrieve all the source code of the url to be scrapped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d433eedc-f102-4e18-bce7-fd906c2de8c3",
   "metadata": {},
   "source": [
    "To connect to the website, we're going to do something different. This time we're going to use the requests module, which sends HTTP requests to retrieve the content of web pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb2426fc-21e0-4594-ab51-6b666e2fcd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://professeur-layton.fandom.com/fr/wiki/En_queue_de_poisson\"\n",
    "# Envoie d'une requête HTTP GET \n",
    "data  = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f54ee0-d7f6-40cc-8575-ff3176a09fc2",
   "metadata": {},
   "source": [
    "The next line is used to check whether the request was successful. The status code 200 indicates success, while other codes (such as 404 or 500) indicate errors :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce2bf7f2-2dd1-48c1-942b-744665b50e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a1d642-945b-4adf-8754-f1103a15f447",
   "metadata": {},
   "source": [
    "We now have code 200, so we can move on to retrieving the HTML content of the web page : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8571896-18db-42f8-bb7d-7f58271c7824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieves the content of the response to the GET request in the form of plain text (HTML)\n",
    "data  = requests.get(url).text\n",
    "# Creation of a BeautifulSoup object using the html5lib parser, which will interpret the raw HTML contained in data\n",
    "soup = BeautifulSoup(data,\"html5lib\")\n",
    "#soup = BeautifulSoup(data,\"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbea220-2a5c-4dc9-ba0a-0d6beb25a7cf",
   "metadata": {},
   "source": [
    "`soup` is the resulting BeautifulSoup object, which makes it easy to navigate and manipulate the structure of the HTML document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c615aae-9c55-4615-99b5-47f661218d68",
   "metadata": {},
   "source": [
    "#### Display page source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50d1fc48-d0ae-4518-91ca-33ce3da52a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ead3f57-2b0f-4d39-b084-098eece9aa66",
   "metadata": {},
   "source": [
    "#### Recovering Web elements from soup.prettify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c2e4cd9-ba53-4656-91d1-ec0b9ffa62e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction of the puzzle title and URL\n",
    "title = soup.find('meta', attrs={'property': \"og:title\"}).get(\"content\")\n",
    "url_enigme = soup.find('meta', attrs={'property': \"og:url\"}).get(\"content\")\n",
    "\n",
    "#print(title, \"\\n\")\n",
    "#print(url_enigme)\n",
    "\n",
    "# Extraction of the number from the table associated with ‘Professor Layton and the Strange Village’.\n",
    "numero = soup.find('a', title=\"Professeur Layton et l'Étrange Village\").find_parent('tr').find_next_sibling('tr').find('td').text.strip()\n",
    "#print(numero, \"\\n\")\n",
    "\n",
    "# Function for extracting the text between a given heading and the following heading\n",
    "def extract_text_between(start_id: str, start_tag: str, stop_tag: str) -> str:\n",
    "    # Find the starting element from the span ID and its parent tag\n",
    "    start_element:Tag = soup.find('span', id=start_id).find_parent(start_tag)\n",
    "    # Initialise an empty list to collect the text\n",
    "    text_list: List[str] = []\n",
    "    # Iterate on all the following elements of the same level\n",
    "    for sibling in start_element.find_next_siblings():\n",
    "        if sibling.name == stop_tag:  # Stop if the end element is reached\n",
    "            break\n",
    "        if sibling.name in ['p', 'ul']:  # Collect text from <p> and <ul> elements\n",
    "            text_list.append(sibling.get_text())\n",
    "    # Join the collected text into a single character string\n",
    "    return \"\\n\".join(text_list)\n",
    "\n",
    "# Extraction of the statement and resolution\n",
    "enigme_enonce = extract_text_between('Énoncé', 'h2', 'h2')\n",
    "reponse = extract_text_between('Résolution', 'h3', 'h3')\n",
    "\n",
    "\n",
    "#print(enigme_enonce)\n",
    "#print(reponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bacc0c8-8755-4446-9174-734631602e21",
   "metadata": {},
   "source": [
    "More information: \n",
    "- The ‘og’ prefix in og:title and og:url refers to the Open Graph Protocol (OGP), a standard used to structure and enrich web page metadata. This protocol was initially developed by Facebook, but is now widely used by various social networking platforms and search engines to better understand and display the information on a web page when it is shared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5e7a14-d5d0-4c06-9712-a0267987be23",
   "metadata": {},
   "source": [
    "`numero = soup.find(‘a’, title=‘Professeur Layton et l'Étrange Village’).find_parent(‘tr’).find_next_sibling(‘tr’).find(‘td’).text.strip()`:\n",
    "- Find the `<a>` tag where the title attribute is equal to ‘Professor Layton and the Strange Village’. This tag corresponds to a hypertext link pointing to ‘Professor Layton and the Strange Village’.\n",
    "- `.find_parent(‘tr’)` : Find the parent element of this `<a>` tag, which is a `<tr>` tag (table row).\n",
    "- `.find_next_sibling(‘tr’)` : Find the next element at the same level as this `<tr>` tag, which is the next `<tr>` tag. This corresponds to the next line in the table.\n",
    "- `.find(‘td’)` : Find the first `<td>` cell in this new `<tr>` line, which probably contains the puzzle number.\n",
    "- `.text.strip()` : Extracts the text contained in this `<td>` cell and deletes the white spaces at the beginning and end of the text with `strip()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e23c021-0b03-457e-9216-634fb285b55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'En queue de poisson', 'number': '053', 'description': 'Alors que vous aviez le dos tourné, quelqu\\'un a englouti le poisson que vous vous étiez préparé pour le dîner. Trois frères se trouvent à proximité des lieux du crime. Voici ce qu\\'ils ont a dire\\xa0:\\n\\nA\\xa0: \"Oui je l\\'ai mangé. C\\'était drôlement bon\\xa0!\"\\nB\\xa0: \"J\\'ai vu A manger le poisson\\xa0!\"\\nC\\xa0: \"B et moi n\\'y avons pas touché.\"\\n\\nL\\'un d\\'entre eux vous ment, mais qui\\xa0?\\n', 'solution': \"Le menteur est le frère C. A et C se sont partagés votre dîner.\\n\\nLa réponse devient évidente quand on réalise que si A ment, alors B ment obligatoirement. Le même raisonnement a lieu si l'on considère que B ment. La seule réponse possible est donc que C est en train de mentir, ce qui implique que C a également touché au poisson.\\n\"}\n"
     ]
    }
   ],
   "source": [
    "# Initialiser le dictionnaire de listes\n",
    "data = {\n",
    "    'title': title,\n",
    "    'number': numero,\n",
    "    'description': enigme_enonce,\n",
    "    'solution': reponse\n",
    "}\n",
    "# Afficher le dictionnaire\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4dd990-fa58-4cf6-9872-dff74dee60f9",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613d866d-d450-44af-8640-a4683b9208a7",
   "metadata": {},
   "source": [
    "## Activity 2: It's your turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e53dc45-7ff5-48c8-bf00-455192957a17",
   "metadata": {},
   "source": [
    "For this activity, we're going to create a more complete table for several puzzles.\n",
    "\n",
    "This time we want a table containing the following columns: `title`, `enigma_num`, `url`, `image`, `enigma`, `solution` for 5 enigmas.\n",
    "\n",
    "We will provide the first part to select 5 riddles. We start by going to a page containing links to all the puzzles in the game : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b60346b6-5eb8-426c-be78-ecaa333fd603",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://professeur-layton.fandom.com/fr/wiki/Cat%C3%A9gorie:%C3%89nigmes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66052869-703b-4afb-8d5a-7639314b1c79",
   "metadata": {},
   "source": [
    "We connect in ‘headless’ mode to save a few lines of code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00dd6921-7f13-4a58-b6cf-8849e10a527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance of Chrome options\n",
    "chrome_options = Options()\n",
    "\n",
    "# Setting Chrome options \n",
    "chrome_options.add_argument('--disable-search-engine-choice-screen') \n",
    "chrome_options.add_argument('--disable-infobars')\n",
    "chrome_options.add_argument('--headless=new')\n",
    "# Create a new instance of the Chrome browser with the specified options\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6274c3-e3b1-4146-8394-bed034efb38d",
   "metadata": {},
   "source": [
    "We retrieve all the href links to the puzzles using a CSS_Selector : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23dae7e7-f64d-4d28-9891-ec4d36b715a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve all <a> elements with the ‘category-page__member-link’ class.\n",
    "elements = driver.find_elements(By.CSS_SELECTOR, \"a.category-page__member-link\")\n",
    "# Extract the hrefs of the elements found\n",
    "hrefs = [element.get_attribute(\"href\") for element in elements]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac26e51f-6c82-4f53-ac3f-1bc3c000edc2",
   "metadata": {},
   "source": [
    "We randomly extract a list of 3 links (to avoid having code that is too long and overloading the wiki with requests) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a65b6f3-3235-4ae4-aa6c-29fc82c7c184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select 3 hrefs\n",
    "hrefs = random.sample(hrefs, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5847ebb9-677d-4f79-8013-8c5b411b402d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://professeur-layton.fandom.com/fr/wiki/Chamailleries',\n",
       " 'https://professeur-layton.fandom.com/fr/wiki/Paf_le_chien_!',\n",
       " 'https://professeur-layton.fandom.com/fr/wiki/La_travers%C3%A9e_(1)']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hrefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8852ba78-e1ba-4a28-8852-8f02825daa8a",
   "metadata": {},
   "source": [
    "We will then create a function which, for each link, retrieves the data we are interested in :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050eddbc-b0e4-4da8-8290-ed4d5aebcf8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
