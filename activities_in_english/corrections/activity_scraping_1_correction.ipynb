{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6f333bd-2609-4858-b410-1414c00cd3d6",
   "metadata": {},
   "source": [
    "# <center>Scraping Workshop</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e655cd2-053b-47a2-baf0-9eabfc01b7dc",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"../images/scrappeur.png\" width=\"600\" height=\"300\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f4c6a6-7867-4f2f-8653-df8ceea4569c",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeb85f9-b3c0-4541-a7cf-9085482f8cdb",
   "metadata": {},
   "source": [
    "Let's start by setting out the basics of scraping. \n",
    "\n",
    "Scraping means knowing how to read what's behind a site. With a simple right-click and `inspect`, it's fairly easy to access the HTML code of the page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a46eec-b1f5-46c9-837f-956dcef224c4",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"../images/du site au html.png\" width=\"800\" height=\"400\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16217df-9864-40bb-adce-41ef1fce2f45",
   "metadata": {},
   "source": [
    "Scraping consists of analysing the source code of a page for various applications:  \n",
    "\n",
    "- Locating elements and interacting with them to automate repetitive tasks (such as buttons, for example)\n",
    "- Extracting different types of information (which we'll be looking at in this workshop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a673eb-db4d-48ac-a680-2c1a2fc47a80",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4de42c-a92c-4cb0-a60f-edcd0f6904d2",
   "metadata": {},
   "source": [
    "Next, you need to choose a scraping tool: ***Selenium*** or ***BeautifulSoup***, which you can use to recover the various elements of a web page.\n",
    "\n",
    "- Selenium is useful for dynamic web pages where content is generated via JavaScript, requiring user interaction such as clicking, scrolling or text input.\n",
    "\n",
    "- BeautifulSoup is a Python library used primarily for parsing HTML and XML documents. It is useful for extracting structured data from static web pages.\n",
    "\n",
    "Generally speaking, we prefer to use Selenium, which allows more actions, but beautifulsoup remains an important option. In this activity, we present the two modules to help you get to grips with them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2df1779-bcb5-484f-827b-4bf04b2f3548",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b651b072-df16-4586-8b2b-6ea80422c1da",
   "metadata": {},
   "source": [
    "## Activity 1a: Retrieving a Professor Layton riddle with Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abe749d-4ac0-44b2-a5f4-a2a1d61f7b69",
   "metadata": {},
   "source": [
    "We're going to see how we can simply retrieve the main elements of a wiki page to create a database. To do this, we're going to connect to https://professeur-layton.fandom.com/fr/wiki/En_queue_de_poisson. \n",
    "\n",
    "The first step will be to retrieve :\n",
    "- the title\n",
    "- the riddle number\n",
    "- the statement\n",
    "- the solution\n",
    "- the solution\n",
    "- the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f454db-be86-4540-b80b-8f78634070c6",
   "metadata": {},
   "source": [
    "#### Importing python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1214a01e-fc63-46f2-9da7-d082a90e10cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee0ba2e-8543-4dc9-8b6c-5fb43f87c517",
   "metadata": {},
   "source": [
    "#### Launch the browser and connect to the riddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e40e8b8a-52fa-458a-8ab5-6ed70c070d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance of Chrome options\n",
    "chrome_options = Options()\n",
    "\n",
    "# Setting Chrome options \n",
    "chrome_options.add_argument('--disable-search-engine-choice-screen') \n",
    "chrome_options.add_argument('--disable-infobars')\n",
    "# Create a new instance of the Chrome browser with the specified options\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# Enter the URL you want to scrape and inject it into the :\n",
    "url = \"https://professeur-layton.fandom.com/fr/wiki/En_queue_de_poisson\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a7540-dfa1-4490-89b7-03ee3cc3af89",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9297082-e62b-4791-bdd7-c5bff09e02a1",
   "metadata": {},
   "source": [
    "If all has worked well, you should see a chrome window open at the URL we've provided. \n",
    "\n",
    "The site uses cookies, we could simply click on ‘ACCEPT ALL’ or ‘REFUSE ALL’ but we're going to use selenium to perform one of these actions. The next two code cells are very specific to the site we're trying to scrape, so we won't dwell on them :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aea1c8a5-178c-4c93-a51a-06f10c2008ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cookie = driver.find_element(By.CLASS_NAME ,'NN0_TB_DIsNmMHgJWgT7U')\n",
    "cookie.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1115dff0-2b04-494a-94c3-c0af195cf5b5",
   "metadata": {},
   "source": [
    "Next, we are going to scroll slightly so that the program can locate the various elements of the site (given the rather large advertising video at the top of the web page) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aefc3ac8-7a7e-4616-a42d-82b27f1c2f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the total height of the page\n",
    "total_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "# Calculate the scroll height (20% in this example)\n",
    "scroll_height = total_height * 0.20\n",
    "\n",
    "# 10% scroll\n",
    "driver.execute_script(f\"window.scrollBy(0, {scroll_height});\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afbea16-20ec-4923-a695-f1203c7a8a17",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21c2454-b1a4-4118-bb83-d7d7cfd31710",
   "metadata": {},
   "source": [
    "We will now look at how to retrieve the information from the instructions: the title, the riddle number, the statement, the solution and the resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd46d9c-4ce6-46d5-8a46-c1e06552e73f",
   "metadata": {},
   "source": [
    "#### Clever recovery of Web elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5560a9-487f-4a04-954c-0d411d2f3365",
   "metadata": {},
   "source": [
    "Here's a little [HTML Form](../form_html.md). It's a quick way of learning or remembering the main tags used to read HTML and identify the different elements of a web page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07ff8bf-f906-477d-aebe-12710764cbc4",
   "metadata": {},
   "source": [
    "This is where we introduce the various Web element selectors : \n",
    "\n",
    "- ID = \"id\"\n",
    "- NAME = \"name\"\n",
    "- XPATH = \"xpath\"\n",
    "- LINK_TEXT = \"link text\"\n",
    "- PARTIAL_LINK_TEXT = \"partial link text\"\n",
    "- TAG_NAME = \"tag name\"\n",
    "- CLASS_NAME = \"class name\"\n",
    "- CSS_SELECTOR = \"css selector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b89c775-44ab-4254-8400-1a71f7eadd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title recovery :\n",
    "title = driver.find_element(By.ID, 'firstHeading')\n",
    "\n",
    "# Riddle number retrieval :\n",
    "num_enigme = driver.find_element(By.XPATH ,'//*[@id=\"mw-content-text\"]/div/div[1]/div[2]/table/tbody/tr[4]/td')\n",
    "\n",
    "# Retrieve the riddle statement :\n",
    "enonce = driver.find_element(By.ID, \"Énoncé\")\n",
    "enigme_enonce = enonce.find_elements(By.XPATH, \"//span[@class='mw-headline' and @id='Énoncé']/ancestor::h2/following-sibling::p[following-sibling::h2]\")\n",
    "\n",
    "# Retrieving the answer :\n",
    "reponse = driver.find_element(By.XPATH, '//*[@id=\"mw-content-text\"]/div/p[8]')\n",
    "\n",
    "resolution = driver.find_element(By.ID, \"Résolution\")\n",
    "resolution_enonce = resolution.find_elements(By.XPATH, \"//span[@class='mw-headline' and @id='Résolution']/ancestor::h3/following-sibling::p[following-sibling::h3]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b1bc32-f286-4fcb-9f41-3149ebcb36d3",
   "metadata": {},
   "source": [
    "Find out what our variables contain and what type they are: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deb77a0e-91f7-4d9e-97bc-5879d9165d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"fbb51fe6914db4fc5a4ca44eb79e66c9\", element=\"f.65A58076A2D8875C15F6000527C46229.d.A360C40CD0FDB00724A24AF066159BD4.e.112\")>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a78eef78-68b9-4dd8-bed3-ba09f9442b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "selenium.webdriver.remote.webelement.WebElement"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca4c42b7-0ec8-436c-8d5a-e16f4d6ff788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"fbb51fe6914db4fc5a4ca44eb79e66c9\", element=\"f.65A58076A2D8875C15F6000527C46229.d.A360C40CD0FDB00724A24AF066159BD4.e.123\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"fbb51fe6914db4fc5a4ca44eb79e66c9\", element=\"f.65A58076A2D8875C15F6000527C46229.d.A360C40CD0FDB00724A24AF066159BD4.e.124\")>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resolution_enonce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fb0cd30-1ba7-4500-9cce-b9ed3ada5bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(resolution_enonce)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d45a493-7cc7-42f3-8929-83e1b98b4159",
   "metadata": {},
   "source": [
    "#### Reading Web elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6605ec55-cb20-4588-86d4-1852ab7f10fb",
   "metadata": {},
   "source": [
    "You will probably have noticed that we have used `find_element` in some cases and `find_elements` in others. \n",
    "\n",
    "The choice between these two methods depends on what we want to obtain. \n",
    "\n",
    "If we want to extract a single element, such as a title, we'll use `find_element`, because we only want to retrieve one element. \n",
    "\n",
    "On the other hand, if we want to retrieve several elements, such as the text tags for a statement or the solution to a puzzle, we'll use `find_elements`, as this allows us to retrieve several elements at once.\n",
    "\n",
    "This way of retrieving elements will have an impact on how they are read. The `.text` method is used to obtain the text of a WebElement.\n",
    "However, if you have a list of WebElements, the `.text` method will not be directly accessible, hence the following code : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43ab2d7f-d104-48c2-9a9b-bab9d8a34ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction of the WebElement title text\n",
    "title = title.text\n",
    "\n",
    "# Extract text from WebElement num_enigme\n",
    "num_enigme = num_enigme.text\n",
    "\n",
    "# Extract text from WebElements list enigme_enonce\n",
    "enigme_enonce = [elem.text for elem in enigme_enonce]\n",
    "enigme_enonce = \"\".join(enigme_enonce)\n",
    "\n",
    "# Extract the text from the WebElement response\n",
    "reponse = reponse.text\n",
    "\n",
    "# Extract text from WebElements list resolution_enonce\n",
    "resolution_enonce = [elem.text for elem in resolution_enonce]\n",
    "resolution_enonce = \"\".join(resolution_enonce)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d377e730-ebbf-4aae-8c74-ccee3087e128",
   "metadata": {},
   "source": [
    "#### Storage in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "079d8e96-471e-4c4b-8643-6492ec52ee80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'En queue de poisson', 'number': '053', 'enonce': 'Alors que vous aviez le dos tourné, quelqu\\'un a englouti le poisson que vous vous étiez préparé pour le dîner. Trois frères se trouvent à proximité des lieux du crime. Voici ce qu\\'ils ont a dire :A : \"Oui je l\\'ai mangé. C\\'était drôlement bon !\"\\nB : \"J\\'ai vu A manger le poisson !\"\\nC : \"B et moi n\\'y avons pas touché.\"L\\'un d\\'entre eux vous ment, mais qui ?', 'solution': 'La réponse est C.', 'resolution': \"Le menteur est le frère C. A et C se sont partagés votre dîner.La réponse devient évidente quand on réalise que si A ment, alors B ment obligatoirement. Le même raisonnement a lieu si l'on considère que B ment. La seule réponse possible est donc que C est en train de mentir, ce qui implique que C a également touché au poisson.\"}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the list dictionary\n",
    "data = {\n",
    "    'title': title,\n",
    "    'number': num_enigme,\n",
    "    'enonce': enigme_enonce,\n",
    "    'solution': reponse,\n",
    "    'resolution': resolution_enonce\n",
    "}\n",
    "# Display the dictionary\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f648a6b0-7c7b-4fa8-9b49-b08c86b09765",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"../images/learner_scraping.png\" width=\"300\" height=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b49282-83e1-4b94-96d3-4c1f07b5df93",
   "metadata": {},
   "source": [
    "And that's it! We've made our first scrapbook!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7387a7-921e-4ba5-b75e-b5d6ce70a10c",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220ed283-9439-45bc-8579-38c92a8427a5",
   "metadata": {},
   "source": [
    "## Activity 1b: Retrieving a Professor Layton riddle with BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af911d8a-3dd1-4ebf-b582-2e8e72b06d04",
   "metadata": {},
   "source": [
    "We're going to do the same scraping, but this time with BeautifulSoup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e864852-a2ae-4ade-b39c-5b22ce681b9d",
   "metadata": {},
   "source": [
    "#### Importing python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b32e7519-3981-4e11-91a2-d9f313eadeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibliothèques\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "from typing import List\n",
    "import requests\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a05b38-e998-4ee4-90ae-3c148945110f",
   "metadata": {},
   "source": [
    "#### Launch a query to retrieve all the source code of the url to be scrapped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d433eedc-f102-4e18-bce7-fd906c2de8c3",
   "metadata": {},
   "source": [
    "To connect to the website, we're going to do something different. This time we're going to use the requests module, which sends HTTP requests to retrieve the content of web pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb2426fc-21e0-4594-ab51-6b666e2fcd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://professeur-layton.fandom.com/fr/wiki/En_queue_de_poisson\"\n",
    "# Envoie d'une requête HTTP GET \n",
    "data  = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f54ee0-d7f6-40cc-8575-ff3176a09fc2",
   "metadata": {},
   "source": [
    "The next line is used to check whether the request was successful. The status code 200 indicates success, while other codes (such as 404 or 500) indicate errors :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce2bf7f2-2dd1-48c1-942b-744665b50e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a1d642-945b-4adf-8754-f1103a15f447",
   "metadata": {},
   "source": [
    "We now have code 200, so we can move on to retrieving the HTML content of the web page : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8571896-18db-42f8-bb7d-7f58271c7824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieves the content of the response to the GET request in the form of plain text (HTML)\n",
    "data  = requests.get(url).text\n",
    "# Creation of a BeautifulSoup object using the html5lib parser, which will interpret the raw HTML contained in data\n",
    "soup = BeautifulSoup(data,\"html5lib\")\n",
    "#soup = BeautifulSoup(data,\"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbea220-2a5c-4dc9-ba0a-0d6beb25a7cf",
   "metadata": {},
   "source": [
    "`soup` is the resulting BeautifulSoup object, which makes it easy to navigate and manipulate the structure of the HTML document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c615aae-9c55-4615-99b5-47f661218d68",
   "metadata": {},
   "source": [
    "#### Display page source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50d1fc48-d0ae-4518-91ca-33ce3da52a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ead3f57-2b0f-4d39-b084-098eece9aa66",
   "metadata": {},
   "source": [
    "#### Recovering Web elements from soup.prettify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c2e4cd9-ba53-4656-91d1-ec0b9ffa62e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction of the puzzle title and URL\n",
    "title = soup.find('meta', attrs={'property': \"og:title\"}).get(\"content\")\n",
    "url_enigme = soup.find('meta', attrs={'property': \"og:url\"}).get(\"content\")\n",
    "\n",
    "#print(title, \"\\n\")\n",
    "#print(url_enigme)\n",
    "\n",
    "# Extraction of the number from the table associated with ‘Professor Layton and the Strange Village’.\n",
    "numero = soup.find('a', title=\"Professeur Layton et l'Étrange Village\").find_parent('tr').find_next_sibling('tr').find('td').text.strip()\n",
    "#print(numero, \"\\n\")\n",
    "\n",
    "# Function for extracting the text between a given heading and the following heading\n",
    "def extract_text_between(start_id: str, start_tag: str, stop_tag: str) -> str:\n",
    "    # Find the starting element from the span ID and its parent tag\n",
    "    start_element:Tag = soup.find('span', id=start_id).find_parent(start_tag)\n",
    "    # Initialise an empty list to collect the text\n",
    "    text_list: List[str] = []\n",
    "    # Iterate on all the following elements of the same level\n",
    "    for sibling in start_element.find_next_siblings():\n",
    "        if sibling.name == stop_tag:  # Stop if the end element is reached\n",
    "            break\n",
    "        if sibling.name in ['p', 'ul']:  # Collect text from <p> and <ul> elements\n",
    "            text_list.append(sibling.get_text())\n",
    "    # Join the collected text into a single character string\n",
    "    return \"\\n\".join(text_list)\n",
    "\n",
    "# Extraction of the statement and resolution\n",
    "enigme_enonce = extract_text_between('Énoncé', 'h2', 'h2')\n",
    "reponse = extract_text_between('Résolution', 'h3', 'h3')\n",
    "\n",
    "\n",
    "#print(enigme_enonce)\n",
    "#print(reponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bacc0c8-8755-4446-9174-734631602e21",
   "metadata": {},
   "source": [
    "More information: \n",
    "- The ‘og’ prefix in og:title and og:url refers to the Open Graph Protocol (OGP), a standard used to structure and enrich web page metadata. This protocol was initially developed by Facebook, but is now widely used by various social networking platforms and search engines to better understand and display the information on a web page when it is shared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5e7a14-d5d0-4c06-9712-a0267987be23",
   "metadata": {},
   "source": [
    "`numero = soup.find(‘a’, title=‘Professeur Layton et l'Étrange Village’).find_parent(‘tr’).find_next_sibling(‘tr’).find(‘td’).text.strip()`:\n",
    "- Find the `<a>` tag where the title attribute is equal to ‘Professor Layton and the Strange Village’. This tag corresponds to a hypertext link pointing to ‘Professor Layton and the Strange Village’.\n",
    "- `.find_parent(‘tr’)` : Find the parent element of this `<a>` tag, which is a `<tr>` tag (table row).\n",
    "- `.find_next_sibling(‘tr’)` : Find the next element at the same level as this `<tr>` tag, which is the next `<tr>` tag. This corresponds to the next line in the table.\n",
    "- `.find(‘td’)` : Find the first `<td>` cell in this new `<tr>` line, which probably contains the puzzle number.\n",
    "- `.text.strip()` : Extracts the text contained in this `<td>` cell and deletes the white spaces at the beginning and end of the text with `strip()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e23c021-0b03-457e-9216-634fb285b55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'En queue de poisson', 'number': '053', 'description': 'Alors que vous aviez le dos tourné, quelqu\\'un a englouti le poisson que vous vous étiez préparé pour le dîner. Trois frères se trouvent à proximité des lieux du crime. Voici ce qu\\'ils ont a dire\\xa0:\\n\\nA\\xa0: \"Oui je l\\'ai mangé. C\\'était drôlement bon\\xa0!\"\\nB\\xa0: \"J\\'ai vu A manger le poisson\\xa0!\"\\nC\\xa0: \"B et moi n\\'y avons pas touché.\"\\n\\nL\\'un d\\'entre eux vous ment, mais qui\\xa0?\\n', 'solution': \"Le menteur est le frère C. A et C se sont partagés votre dîner.\\n\\nLa réponse devient évidente quand on réalise que si A ment, alors B ment obligatoirement. Le même raisonnement a lieu si l'on considère que B ment. La seule réponse possible est donc que C est en train de mentir, ce qui implique que C a également touché au poisson.\\n\"}\n"
     ]
    }
   ],
   "source": [
    "# Initialiser le dictionnaire de listes\n",
    "data = {\n",
    "    'title': title,\n",
    "    'number': numero,\n",
    "    'description': enigme_enonce,\n",
    "    'solution': reponse\n",
    "}\n",
    "# Afficher le dictionnaire\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4dd990-fa58-4cf6-9872-dff74dee60f9",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613d866d-d450-44af-8640-a4683b9208a7",
   "metadata": {},
   "source": [
    "## Activity 2: Generalising several puzzles with Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e53dc45-7ff5-48c8-bf00-455192957a17",
   "metadata": {},
   "source": [
    "For this activity, we're going to create a more complete table for several puzzles.\n",
    "\n",
    "This time we want a table containing the following columns: `title`, `enigma_num`, `url`, `image`, `enigma`, `solution` for 5 enigmas.\n",
    "\n",
    "We will provide the first part to select 5 riddles. We start by going to a page containing links to all the puzzles in the game : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b60346b6-5eb8-426c-be78-ecaa333fd603",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://professeur-layton.fandom.com/fr/wiki/Cat%C3%A9gorie:%C3%89nigmes\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66052869-703b-4afb-8d5a-7639314b1c79",
   "metadata": {},
   "source": [
    "We connect in ‘headless’ mode to save a few lines of code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00dd6921-7f13-4a58-b6cf-8849e10a527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance of Chrome options\n",
    "chrome_options = Options()\n",
    "\n",
    "# Setting Chrome options \n",
    "chrome_options.add_argument('--disable-search-engine-choice-screen') \n",
    "chrome_options.add_argument('--disable-infobars')\n",
    "chrome_options.add_argument('--headless=new')\n",
    "# Create a new instance of the Chrome browser with the specified options\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6274c3-e3b1-4146-8394-bed034efb38d",
   "metadata": {},
   "source": [
    "We retrieve all the href links to the puzzles using a CSS_Selector : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23dae7e7-f64d-4d28-9891-ec4d36b715a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve all <a> elements with the ‘category-page__member-link’ class.\n",
    "elements = driver.find_elements(By.CSS_SELECTOR, \"a.category-page__member-link\")\n",
    "# Extract the hrefs of the elements found\n",
    "hrefs = [element.get_attribute(\"href\") for element in elements]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac26e51f-6c82-4f53-ac3f-1bc3c000edc2",
   "metadata": {},
   "source": [
    "We randomly extract a list of 3 links (to avoid having code that is too long and overloading the wiki with requests) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a65b6f3-3235-4ae4-aa6c-29fc82c7c184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select 3 hrefs\n",
    "hrefs = random.sample(hrefs, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5847ebb9-677d-4f79-8013-8c5b411b402d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://professeur-layton.fandom.com/fr/wiki/Chamailleries',\n",
       " 'https://professeur-layton.fandom.com/fr/wiki/Paf_le_chien_!',\n",
       " 'https://professeur-layton.fandom.com/fr/wiki/La_travers%C3%A9e_(1)']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hrefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8852ba78-e1ba-4a28-8852-8f02825daa8a",
   "metadata": {},
   "source": [
    "We will then create a function which, for each link, retrieves the data we are interested in :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c02e242f-8335-419d-92ee-13a569f8fbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "def collecte_enigme(href):\n",
    "    url = href\n",
    "    \n",
    "    # Browser configuration (Chrome in this example)\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "    chrome_options.add_argument('--disable-search-engine-choice-screen') \n",
    "    chrome_options.add_argument('--disable-infobars')\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    \n",
    "    # Open the web page\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        cookie = driver.find_element(By.XPATH ,'/html/body/div[7]/div/div/div[2]/div[2]/div[1]')\n",
    "        cookie.click()\n",
    "    except :\n",
    "        pass\n",
    "    try : \n",
    "        # Title recovery :\n",
    "        title = driver.find_element(By.ID, 'firstHeading')\n",
    "        title = title.text\n",
    "    except : \n",
    "        title = None\n",
    "    try:\n",
    "        time.sleep(4)\n",
    "        num_enigme = driver.find_element(By.XPATH ,'//*[@id=\"mw-content-text\"]/div/div[1]/div[2]/table/tbody/tr[4]/td')\n",
    "        num_enigme = num_enigme.text\n",
    "       \n",
    "    except :\n",
    "        num_enigme = None\n",
    "    try:\n",
    "        \n",
    "        # Image recovery\n",
    "        image_element = driver.find_element(By.CSS_SELECTOR, 'div.floatnone img')\n",
    "        image = image_element.get_attribute(\"src\")\n",
    "    \n",
    "    except:\n",
    "        image=None\n",
    "    \n",
    "    # Retrieve the statement of the riddle :\n",
    "    enigme_enonce = None\n",
    "    try : \n",
    "        enonce = driver.find_element(By.ID, \"Énoncé\")\n",
    "        enigme_enonce = enonce.find_elements(By.XPATH, \"//span[@class='mw-headline' and @id='Énoncé']/ancestor::h2/following-sibling::p[following-sibling::h2]\")\n",
    "        enigme_enonce = \"\".join([elem.text for elem in enigme_enonce])\n",
    "    except NoSuchElementException:\n",
    "        enigme_enonce = image\n",
    "        \n",
    "    resolution_title = None\n",
    "    \n",
    "    try:\n",
    "        resolution_title = driver.find_element(By.ID, \"Résolution\")\n",
    "        resolution = resolution_title.find_elements(By.XPATH, \"//span[@class='mw-headline' and @id='Résolution']/ancestor::h3/following-sibling::p[following-sibling::h3]\")\n",
    "        resolution = \"\\n\".join([elem.text for elem in resolution])\n",
    "    except Exception:\n",
    "        try:\n",
    "            solution = driver.find_element(By.ID, \"Solution\")\n",
    "            # Find the first ‘div’ sibling of ‘Solution’ that contains the slideshow\n",
    "            slideshow_div = solution.find_element(By.XPATH, '//*[@id=\"slideshow-0\"]/div/div[1]')\n",
    "\n",
    "            # Locate the specific image within this slideshow\n",
    "            image_element = slideshow_div.find_element(By.XPATH, './/img[@class=\"thumbimage\"]')\n",
    "            image_url = image_element.get_attribute('src')\n",
    "            resolution = image_url\n",
    "        except : \n",
    "            text_elements = solution.find_elements(By.XPATH, 'following::p')\n",
    "            resolution = \"\\n\".join([elem.text for elem in text_elements])\n",
    " \n",
    "    # Creating the DataFrame\n",
    "    return pd.DataFrame([{'title': title, 'num_enigme':num_enigme, 'url': url, 'image': image, 'enigme': enigme_enonce, 'solution': resolution}])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58839a0-1d23-47ea-8c03-07577cd76f2f",
   "metadata": {},
   "source": [
    "We then use this function to create our DataFrame :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87629b8c-91d2-4532-9e9d-e64bb76b8aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping de la page https://professeur-layton.fandom.com/fr/wiki/Chamailleries en cours...\n",
      "Scraping de la page https://professeur-layton.fandom.com/fr/wiki/Paf_le_chien_! en cours...\n",
      "Scraping de la page https://professeur-layton.fandom.com/fr/wiki/La_travers%C3%A9e_(1) en cours...\n",
      "Fin du Scraping\n"
     ]
    }
   ],
   "source": [
    "df_final = pd.DataFrame()\n",
    "for href in hrefs:\n",
    "    print(\"Scraping de la page\", href, \"en cours...\")\n",
    "    df_final = pd.concat([df_final, collecte_enigme(href)], ignore_index=True)\n",
    "print(\"Fin du Scraping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1037ac10-3d1f-4120-b840-53e2b7e81b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>num_enigme</th>\n",
       "      <th>url</th>\n",
       "      <th>image</th>\n",
       "      <th>enigme</th>\n",
       "      <th>solution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chamailleries</td>\n",
       "      <td>027</td>\n",
       "      <td>https://professeur-layton.fandom.com/fr/wiki/C...</td>\n",
       "      <td>https://static.wikia.nocookie.net/layton/image...</td>\n",
       "      <td>Six frères se réunissent autour d'une table po...</td>\n",
       "      <td>Beau travail !\\nPlacez les garçons comme le mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paf le chien !</td>\n",
       "      <td>009</td>\n",
       "      <td>https://professeur-layton.fandom.com/fr/wiki/P...</td>\n",
       "      <td>https://static.wikia.nocookie.net/layton/image...</td>\n",
       "      <td>Les allumettes ci-dessous représentent un chie...</td>\n",
       "      <td>La voiture a aplati le pauvre chien ! Il faut ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>La traversée (1)</td>\n",
       "      <td>007</td>\n",
       "      <td>https://professeur-layton.fandom.com/fr/wiki/L...</td>\n",
       "      <td>https://static.wikia.nocookie.net/layton/image...</td>\n",
       "      <td>Vous devez amener les trois loups et les trois...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              title num_enigme  \\\n",
       "0     Chamailleries        027   \n",
       "1    Paf le chien !        009   \n",
       "2  La traversée (1)        007   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://professeur-layton.fandom.com/fr/wiki/C...   \n",
       "1  https://professeur-layton.fandom.com/fr/wiki/P...   \n",
       "2  https://professeur-layton.fandom.com/fr/wiki/L...   \n",
       "\n",
       "                                               image  \\\n",
       "0  https://static.wikia.nocookie.net/layton/image...   \n",
       "1  https://static.wikia.nocookie.net/layton/image...   \n",
       "2  https://static.wikia.nocookie.net/layton/image...   \n",
       "\n",
       "                                              enigme  \\\n",
       "0  Six frères se réunissent autour d'une table po...   \n",
       "1  Les allumettes ci-dessous représentent un chie...   \n",
       "2  Vous devez amener les trois loups et les trois...   \n",
       "\n",
       "                                            solution  \n",
       "0  Beau travail !\\nPlacez les garçons comme le mo...  \n",
       "1  La voiture a aplati le pauvre chien ! Il faut ...  \n",
       "2                                                     "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_row', 5)\n",
    "pd.set_option('display.max_column', 6)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f6a15ac-87fc-4319-9428-f9c622e8096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Permet de mettre fin au driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92163375-fd98-47d7-9f1f-02ef3ce61d00",
   "metadata": {},
   "source": [
    "## Activity 2: Generalising several puzzles with BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3a73f1-7f1d-4772-8bb0-a77624b5b1e6",
   "metadata": {},
   "source": [
    "#### Launch a query to retrieve all the source code of the url to be scrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b107ff9-1051-4bff-bfd9-af8824328b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://professeur-layton.fandom.com/fr/wiki/Cat%C3%A9gorie:%C3%89nigmes\"\n",
    "data  = requests.get(url).text\n",
    "soup = BeautifulSoup(data,\"html5lib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ecca56-e498-4c9b-8749-eb9f39025349",
   "metadata": {},
   "source": [
    "#### Display page source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b45dc254-8e02-4e3b-aa78-297b2c1a621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1ea655-d96a-4e0d-882a-7d789e1d39ec",
   "metadata": {},
   "source": [
    "#### Collect all puzzle links and take only 5 at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0c547ee-5a10-4401-b070-b8d08e66f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trouver tous les éléments <a> avec la classe \"category-page__member-link\"\n",
    "links = soup.find_all('a', class_='category-page__member-link')\n",
    "\n",
    "# Extraire les attributs href\n",
    "hrefs = [link.get('href') for link in links]\n",
    "\n",
    "# Afficher les hrefs\n",
    "#print(hrefs)\n",
    "#print(len(hrefs))\n",
    "\n",
    "# Sélectionner aléatoirement 5 hrefs\n",
    "hrefs = random.sample(hrefs, 5)\n",
    "\n",
    "# Afficher les hrefs sélectionnés aléatoirement\n",
    "#print(random_hrefs)\n",
    "#print(len(random_hrefs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64fd639-3e47-48a7-895c-8c4357dd072d",
   "metadata": {},
   "source": [
    "#### Let's create a function to repeat the data extraction steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df501c30-439c-4881-86b0-4d2be844c172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collecte_enigme(racine, href):\n",
    "    url = racine+href\n",
    "    data  = requests.get(url).text\n",
    "    soup = BeautifulSoup(data,\"html.parser\")\n",
    "  \n",
    "    # Récupération du titre\n",
    "    title = soup.find('meta', attrs={'property': \"og:title\"})\n",
    "    title = title.get(\"content\")\n",
    "\n",
    "    # Récupération url\n",
    "    url_enigme = soup.find('meta', attrs={'property': \"og:url\"})\n",
    "    url_enigme = url_enigme.get(\"content\")\n",
    "\n",
    "    # Récupération de l'image\n",
    "    src_tags = soup.find_all(src=True)\n",
    "    # Extraire les valeurs de src\n",
    "    src_urls = [tag['src'] for tag in src_tags]\n",
    "    longest_src = max(src_urls, key=len) if src_urls else None\n",
    "    image = longest_src\n",
    "\n",
    "    # Récupération de l'énigme\n",
    "    try:\n",
    "        enigme_title = soup.find('span', {'class': 'mw-headline', 'id': 'Énoncé'})\n",
    "        # Trouver le paragraphe suivant le titre de la section \"Énoncé\"\n",
    "        enigme_paragraph = enigme_title.find_next('p')\n",
    "        # Extraire le texte du paragraphe\n",
    "        enigme = enigme_paragraph.get_text(strip=True)\n",
    "        \n",
    "    except :\n",
    "        enigme = image\n",
    "        \n",
    "    # Récupération de la réponse\n",
    "    try :\n",
    "        \n",
    "        reponse_title = soup.find('span', {'class': 'mw-headline', 'id': 'Solution'})\n",
    "        reponse_paragraph = reponse_title.find_next('p')\n",
    "        reponse = reponse_paragraph.get_text(strip=True)\n",
    "    except :\n",
    "        a_tag = soup.find('a', class_='image')\n",
    "        if a_tag:\n",
    "            reponse = a_tag.get('href')\n",
    "        else:\n",
    "            reponse =\"La réponse n'a pas été loadé correctement\"\n",
    "\n",
    "    # Récupération des indices\n",
    "    tabs = soup.select('ul.wds-tabs li.wds-tabs__tab a')\n",
    "    contents = soup.select('div.wds-tab__content')\n",
    "    # Extract each index content into a list\n",
    "    indices = []\n",
    "    for i, tab in enumerate(tabs):\n",
    "        if i < len(contents):\n",
    "            content_divs = contents[i].select('div[style*=\"overflow-y:auto\"]')\n",
    "            if content_divs:\n",
    "                content = content_divs[0].get_text(strip=True)\n",
    "                indices.append(content)\n",
    "        \n",
    "    # Append the collected data as a dictionary\n",
    "    data = []\n",
    "    data.append({'title': title, 'url': url_enigme, 'image': image, 'enigme': enigme, 'indices': indices,'solution': reponse})\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2a839e-1db8-4d74-9a8b-802bf0892707",
   "metadata": {},
   "source": [
    "#### Using the function and storing it in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57b83f25-c3b8-49c1-bb69-e5d43993dc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "racine = \"https://professeur-layton.fandom.com\"\n",
    "df_final = pd.DataFrame()\n",
    "for href in hrefs:\n",
    "    #print(href)\n",
    "    df_final = pd.concat([df_final, collecte_enigme(racine,href)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145124c0-949a-435a-b620-98c23523a31a",
   "metadata": {},
   "source": [
    "#### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "059c5314-9042-4de1-8e89-0396335db08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>image</th>\n",
       "      <th>enigme</th>\n",
       "      <th>indices</th>\n",
       "      <th>solution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dédale numérique</td>\n",
       "      <td>https://professeur-layton.fandom.com/fr/wiki/D...</td>\n",
       "      <td>https://static.wikia.nocookie.net/layton/image...</td>\n",
       "      <td>Essayez de sortir de ce labyrinthe ! Commencez...</td>\n",
       "      <td>[Si vous essayez tous les itinéraires possible...</td>\n",
       "      <td>Par ici la sortie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tas de feuilles</td>\n",
       "      <td>https://professeur-layton.fandom.com/fr/wiki/T...</td>\n",
       "      <td>https://static.wikia.nocookie.net/layton/image...</td>\n",
       "      <td>Plusieurs feuilles de calque ont été superposé...</td>\n",
       "      <td>[Trois couches ici, quatre couches là...Marque...</td>\n",
       "      <td>La réponse est 5.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tenir l'affiche</td>\n",
       "      <td>https://professeur-layton.fandom.com/fr/wiki/T...</td>\n",
       "      <td>https://static.wikia.nocookie.net/layton/image...</td>\n",
       "      <td>Alors que Benny s'appliquait à placarder des a...</td>\n",
       "      <td>[Il est plus simple d'éliminer les affiches di...</td>\n",
       "      <td>Il suffit de cocher l'affiche B.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inéquations ?</td>\n",
       "      <td>https://professeur-layton.fandom.com/fr/wiki/I...</td>\n",
       "      <td>https://static.wikia.nocookie.net/layton/image...</td>\n",
       "      <td>Eh bien, on dirait que quelqu'un a encore écri...</td>\n",
       "      <td>[Au premier coup d'œil, il semble que l'auteur...</td>\n",
       "      <td>La réponse est 1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alchimie en folie 01</td>\n",
       "      <td>https://professeur-layton.fandom.com/fr/wiki/A...</td>\n",
       "      <td>https://static.wikia.nocookie.net/layton/image...</td>\n",
       "      <td>https://static.wikia.nocookie.net/layton/image...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Solution à l'énigme.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                                                url  \\\n",
       "0      Dédale numérique  https://professeur-layton.fandom.com/fr/wiki/D...   \n",
       "1       Tas de feuilles  https://professeur-layton.fandom.com/fr/wiki/T...   \n",
       "2       Tenir l'affiche  https://professeur-layton.fandom.com/fr/wiki/T...   \n",
       "3         Inéquations ?  https://professeur-layton.fandom.com/fr/wiki/I...   \n",
       "4  Alchimie en folie 01  https://professeur-layton.fandom.com/fr/wiki/A...   \n",
       "\n",
       "                                               image  \\\n",
       "0  https://static.wikia.nocookie.net/layton/image...   \n",
       "1  https://static.wikia.nocookie.net/layton/image...   \n",
       "2  https://static.wikia.nocookie.net/layton/image...   \n",
       "3  https://static.wikia.nocookie.net/layton/image...   \n",
       "4  https://static.wikia.nocookie.net/layton/image...   \n",
       "\n",
       "                                              enigme  \\\n",
       "0  Essayez de sortir de ce labyrinthe ! Commencez...   \n",
       "1  Plusieurs feuilles de calque ont été superposé...   \n",
       "2  Alors que Benny s'appliquait à placarder des a...   \n",
       "3  Eh bien, on dirait que quelqu'un a encore écri...   \n",
       "4  https://static.wikia.nocookie.net/layton/image...   \n",
       "\n",
       "                                             indices  \\\n",
       "0  [Si vous essayez tous les itinéraires possible...   \n",
       "1  [Trois couches ici, quatre couches là...Marque...   \n",
       "2  [Il est plus simple d'éliminer les affiches di...   \n",
       "3  [Au premier coup d'œil, il semble que l'auteur...   \n",
       "4                                                 []   \n",
       "\n",
       "                           solution  \n",
       "0                Par ici la sortie.  \n",
       "1                 La réponse est 5.  \n",
       "2  Il suffit de cocher l'affiche B.  \n",
       "3                 La réponse est 1.  \n",
       "4              Solution à l'énigme.  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_row', 7)\n",
    "pd.set_option('display.max_column', 6)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2e582c-54d1-4617-82ae-d05b7ec943bf",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137e12c8-22b2-407b-94df-ae5e7601e28d",
   "metadata": {},
   "source": [
    "We finally succeeded in building a DataFrame from a website! \n",
    "The important thing to remember is that BeautifulSoup is very useful for so-called “open” sites and for the massive repetition of information gathering."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
